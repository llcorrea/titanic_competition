# -*- coding: utf-8 -*-
"""Titanic_comp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_pZiDRMXscF8V4jcuBWW5Dy8Pa0lhI1f

# **Titanic - Machine Learning from Disaster**

Titanic Dataset from Kaggle Competition
"""

import sys
import io
import pdb
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold, RepeatedKFold
from sklearn.linear_model import LogisticRegression 
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from google.colab import files
import re

"""# **Loading CSV files into Colab from a local drive**"""

try:
  train_data = pd.read_csv('train.csv')  
except:
  uploaded = files.upload()
  train_data = pd.read_csv('train.csv')

try:
  test_data = pd.read_csv('test.csv')
except:
  uploaded = files.upload()
  test_data = pd.read_csv(io.BytesIO(uploaded['test.csv']))

"""# **EDA step**

> **Total de dados:** 891 registros\
> **Total de features:** 12 features\
> **Feature alvo:** Survived

* Cada registro representa um passageiro do Titanic.

* A feature alvo (Survived) indica se um determinado passageiro sobreviveu ou não ao naufrágio. 

* Survived é utilizada na formulação do problema de ML, que visa prever se um determinado passageiro sobreviveu ou não considerando os outros 11 atributos do dataset.
"""

print(train_data.head())
print(test_data.head())

#print(train_data.shape)
#print(train_data.tail())
#print(train_data.columns)
#print(train_data.describe())
print(train_data.info())
#print(train_data.isnull().sum())

"""**Análise das features mais relevantes:**

> **Feature Survived:** Indica se o passageiro sobreviveu ou não ao naufrágio.

* Sem dados faltantes.
* Valores desbalanceados, onde 62% (549) das pessoas morreram e 38% (342) sobreviveram.
* Nota-se que a sobrevivência está relacionada ao número de botes e coletes salva-vidas disponíveis no navio. Fica evidente que não havia material de resgate para todos os passageiros. 
* Considera-se também alguns casos onde as pessoas não conseguiram chegar à área externa, permanecendo presas dentro do navio.
"""

var='Survived' #indica se a pessoa sobreviveu ou não
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 62% das pessoas morreram
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature

ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xticklabels(labels=['Died', 'Survived'])

"""> **Feature Sex:**

* Sem dados faltantes.
* Valores desbalanceados, onde 65% (577) das pessoas eram homens e 35% (314) eram mulheres.

> **Q1: Sabe-se que mulheres e crianças tenderam a serem salvas primeiro. Existe relação entre as pessoas que não sobreviveram e o sexo masculino?**
"""

var='Sex'
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 65% das pessoas eram homens
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_xlabel('Sex')
ax.set_ylabel('Number of People')

"""> **Feature Age:**

> Distribuição dos valores:\
**count:**     714\
**missing:**   177\
**mean:**      29.7 anos\
**std:**       14.5 anos\
**min:**      0.4 anos\
**25%:**       20.1 anos\
**50%:**       28 anos\
**75%:**      38 anos\
**max:**       80 anos

* **Dados faltantes (177).**
* Valores desbalanceados, variando entre 0.4 e 80 anos.
* 50% das pessoas apresentam menos de 28 anos.
* 75% das pessoas apresentam menos de 38 anos.
* Maior concentração de pessoas com idades entre 18 e 40 anos.

> * Porcentagem de pessoas com menos de 15 anos (crianças?):  8.75% (78)
* Porcentagem de pessoas com menos de 18 anos:  12.68% (113)
* Porcentagem de pessoas do sexo masculino com menos de 18 anos:  6.51% (58)
* Porcentagem de pessoas do sexo feminino com menos de 18 anos:  6.17% (55)
* Porcentagem de pessoas entre 18 e 40 anos:  50.62% (451)
* Porcentagem de pessoas entre 41 e 65 anos:  15.71% (140)
* Porcentagem de pessoas com mais de 65 anos:  0.9% (8)
"""

var='Age'
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
#print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, maior concentração de pessoas com idades entre 20 e 40 anos
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
print(train_data[var].describe(), '\n')
ax=train_data[var].hist(bins=30)
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Age')

print('Porcentagem de pessoas com menos de 15 anos (crianças?): ', len(train_data[train_data['Age']<15])/len(train_data)*100, len(train_data[train_data['Age']<15]))
print('Porcentagem de pessoas com menos de 18 anos: ', len(train_data[train_data['Age']<18])/len(train_data)*100, len(train_data[train_data['Age']<18]))
print('Porcentagem de pessoas do sexo masculino com menos de 18 anos: ', len(train_data[(train_data['Age']<18) & (train_data['Sex']=='male')])/len(train_data)*100, len(train_data[(train_data['Age']<18) & (train_data['Sex']=='male')]))
print('Porcentagem de pessoas do sexo feminino com menos de 18 anos: ', len(train_data[(train_data['Age']<18) & (train_data['Sex']=='female')])/len(train_data)*100, len(train_data[(train_data['Age']<18) & (train_data['Sex']=='female')]))
print('Porcentagem de pessoas entre 18 e 40 anos: ', len(train_data[(train_data['Age']>=18) & (train_data['Age']<=40)])/len(train_data)*100, len(train_data[(train_data['Age']>=18) & (train_data['Age']<=40)]))
print('Porcentagem de pessoas entre 41 e 65 anos: ', len(train_data[(train_data['Age']>=41) & (train_data['Age']<=65)])/len(train_data)*100, len(train_data[(train_data['Age']>=41) & (train_data['Age']<=65)]))
print('Porcentagem de pessoas com mais de 65 anos: ', len(train_data[(train_data['Age']>=66)])/len(train_data)*100, len(train_data[(train_data['Age']>=66)]))

"""> **Feature Pclass:** Indica a classe ocupada no navio, sendo elas: classe 1 (primeira classe), classe 2 (intermediária) e classe 3 (mais econômica).

* Sem dados faltantes.
* Valores desbalanceados, onde 55% (491) das pessoas ocupam a classe 3ª classe (mais econômica), 21% (184) ocupam a 2ª classe (intermediária) e 24% (216) estão na primeira classe (mais cara).

> **Q2: Considerando os homens que sobreviveram, existe alguma relação com a classe ocupada? E as mulheres que não sobreviveram, pertenciam a alguma classe específica?**
"""

var='Pclass' #indica a classe no navio (1, 2 e 3)
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 55% das pessoas ocuparam a classe 3 (mais barata), 25% a classe 2 (intermediária) e 20% a primeira classe (mais ricos)
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Class')
ax.tick_params(axis='x', labelrotation=0)

"""> **Feature Fare:** Indica o valor da passagem utilizada pelo passageiro.

> Distribuição dos valores:\
**count:**    891\
**missing:**  0\
**mean:**     32.2\
**std:**      49.7\
**min:**      0\
**25%:**      7.9\
**50%:**      14.5\
**75%:**      31\
**max:**      512.3

* Valores desbalanceados, variando entre 0 e 512:
* 75% das pessoas pagaram valores inferiores a 31.
* Maior parte das pessoas pagaram valores de passagem entre 0 e 50.

* Porcentagem de pessoas que pagaram até 50:  81.9%\
* Porcentagem de pessoas que pagaram até 100:  94.1%

> **Discriminação dos valores de passagens para pessoas da classe 3 (classe mais econômica):**\
count:     491\
mean:      13.675550\
std:       11.778142\
min:        0.000000\
25%:        7.750000\
50%:        8.050000\
75%:       15.500000\
max:       69.550000

> **Discriminação dos valores de passagens para pessoas da classe 2:**\
count:     184\
mean:     20.662183\
std:       13.417399\
min:       0.000000\
25%:       13.000000\
50%:       14.250000\
75%:       26.000000\
max:       73.500000

> **Discriminação dos valores de passagens para pessoas da classe 1 (classe mais cara):**\
count:     216\
mean:      84.154687\
std:      78.380373\
min:       0.000000\
25%:       30.923950\
50%:       60.287500\
75%:       93.500000\
max:       512.329200

> **Q3: O preço da passagem está relacionado com a classe ocupada?**
"""

var='Fare' #indica o valor da passagem
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde a maior parte das pessoas pagaram entre 0 e 100. Feature variando entre 0 e 512.
#print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
print(train_data[var].describe(), '\n')

ax=train_data[var].hist(bins=50)
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Fare')

print('Porcentagem de pessoas que pagaram até 50: ', len(train_data[train_data['Fare']<50])/len(train_data)*100)
print('Porcentagem de pessoas que pagaram até 100: ', len(train_data[train_data['Fare']<100])/len(train_data)*100)
print('\n')

print('Valores de passagens para classe 3:\n', train_data['Fare'][train_data['Pclass']==3].describe(), '\n')
print('Valores de passagens para classe 2:\n',train_data['Fare'][train_data['Pclass']==2].describe(), '\n')
print('Valores de passagens para classe 1:\n',train_data['Fare'][train_data['Pclass']==1].describe(), '\n')

"""> **Feature Parch:** Indica com quantos acompanhantes a pessoa estava viajando, sendo eles pais ou filhos.

* Sem dados faltantes.
* Valores desbalanceados, onde 76% (678) das pessoas estavam viajando sem os pais ou filhos;
* 13% (118) estavam viajando com apenas um desses acompanhantes;
* 9% (80) viajavam com dois desses acompanhantes.
"""

var='Parch' #indica com quantos acompanhantes a pessoa estava viajando, sendo eles pais ou filhos
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 76% das pessoas estavam viajando sem os pais ou filhos
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Number of Parents and Children')
ax.tick_params(axis='x', labelrotation=0)

"""> **Feature SibSp:** Indica com quantos acompanhantes a pessoa estava viajando, sendo eles irmãos ou cônjuge.

* Sem dados faltantes.
* Valores desbalanceados, onde 78% (608) das pessoas estavam viajando sem irmãos ou cônjuge; 
* 23% (209) estavam viajando com apenas um desses acompanhantes.
"""

var='SibSp' #indica com quantos acompanhantes a pessoa estava viajando, sendo eles irmãos ou cônjuge
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 78% das pessoas estavam viajando sem irmãos ou cônjuge
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Number of Siblings and Spouse')
ax.tick_params(axis='x', labelrotation=0)

"""> **Feature Parch e SibSp: Soma das duas features para representar o total de acompanhantes de um passageiro, sendo eles pais, filhos, irmãos ou cônjuge.**

* Valores desbalanceados, onde 60% (537) das pessoas estavam viajando sozinhas;
* 18% (161) estavam viajando com apenas um acompanhante.
* 11% (102) estavam viajando com dois acompanhantes.

* Total de pessoas com um ou mais acompanhantes: 354 (40%) pessoas.
* Total de pessoas com mais de um acompanhante, sendo pelo menos um pai ou filho e um irmão ou cônjuge:  142 (16%) pessoas.

* **Q4: Desconsiderando mulheres e crianças, homens com acompanhantes tenderam a sobreviver mais? Ou ainda, homens ricos e acompanhados tiveram mais chances?**
"""

train_data['Parch_SibSp']=train_data['Parch']+train_data['SibSp']
train_data['Parch_SibSp'].describe()

var='Parch_SibSp' #indica com quantos acompanhantes a pessoa estava viajando
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 60% das pessoas estavam viajando sozinhas
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature

ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Number of Companions')
ax.tick_params(axis='x', labelrotation=0)

print('Total de pessoas com um ou mais acompanhantes: ', len(train_data[(train_data['Parch_SibSp']>0)]))
print('Total de pessoas com mais de um acompanhante, sendo pai ou filho e irmão ou cônjuge: ', len(train_data[(train_data['Parch']>0) & (train_data['SibSp']>0)]), len(train_data[(train_data['Parch']>0) & (train_data['SibSp']>0)])/len(train_data)*100)

"""> **Feature Embarked:** Indica a estação de embarque do passageiro.

* **Dados faltantes (2).**
* Valores desbalanceados, onde 72% (644) pessoas embarcaram no porto S;
* 19% (168) embarcaram em C;
* 9% (77) embarcaram em Q.
"""

var='Embarked' #indica com quantos acompanhantes a pessoa estava viajando, sendo eles irmãos ou cônjuge
print('Total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n%s\n' % (var, train_data[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde 78% das pessoas estavam viajando sem irmãos ou cônjuge
print('Classes de valores únicos da feature %s:\n%s\n'  % (var, train_data[var].unique())) #descrição dos valores únicos da feature
ax=train_data[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)
ax.set_ylabel('Number of People')
ax.set_xlabel('Boarding Place')
ax.tick_params(axis='x', labelrotation=0)

"""# **Relation between features**

"""

#groupby
display(train_data.groupby(['Sex', 'Survived', 'Pclass']).mean())

"""> **Relação entre as features Age e Sex:**

* **Através dos gráficos, percebe-se uma similaridade entre a distribuição das idades de homens e mulheres.**

* No entanto, no navio haviam mais homens do que mulheres, conforme análise prévia: 65% (577) das pessoas eram homens e 35% (314) eram mulheres.

* **Assim, a sobrevivência de mais mulheres não está relacionada com a idade das pessoas e sim com a prioridade dada ao sexo feminino.**

"""

sns.set()
plt.figure(figsize=(10, 8))
sns.boxplot(y='Age', x='Sex', data=train_data)
plt.show()

plt.figure(figsize=(10, 8))
sns.violinplot(y='Age', x='Sex', data=train_data)
plt.show()

"""> **Relação entre as features Age e Survived:**

* **Percebe-se uma similaridade entre a distribuição das idades das pessoas que sobreviveram e que morreram.**

* No entanto, mais pessoas morreram (62% - 549) do que sobreviveram (38% - 342).

* **Assim, notamos que apesar da prioridade dada as crianças, algumas também morreram.**
"""

sns.set()
plt.figure(figsize=(10, 8))
sns.boxplot(y='Age', x='Survived', data=train_data)

"""> **Relação entre as features Sex e Survived:**

* **Considerando que haviam no navio mais homens do que mulheres, proporcionalmente a cada categoria, percebe-se que mais mulheres sobreviveram em relação aos homens.**

> **Resposta Q1: Sabe-se que mulheres e crianças tenderam a serem salvas primeiro. Existe relação entre as pessoas que não sobreviveram e o sexo masculino? Sim, mais homens morreram em comparação com as mulheres.**
"""

display(pd.crosstab([train_data['Sex']], train_data['Survived']))

display(pd.crosstab([train_data['Sex']], train_data['Survived'], normalize='index'))

pd.crosstab([train_data['Sex']], train_data['Survived']).plot.bar()
plt.ylabel('Number of People')

"""> **Relação entre as features Sex, Survived e Pclass:**

* Considerando que mais homens morreram, e haviam mais homens na classe 3, proporcionalmente a cada categoria de Pclass, percebe-se que os homens da primeira classe tiveram prioridade no salvamento.

* Os homens da primeira classe, mesmo em menos número, foram os que mais sobreviveram.

> **Resposta Q2: Considerando os homens que sobreviveram, existe alguma relação com a classe ocupada? Proporcionalmente ao total de homens em cada categoria de Pclass, os homens da primeira classe sobreviveram em maior número.**

> **Resposta Q2: E as mulheres que não sobreviveram, pertenciam a alguma classe específica? Assim como no caso anterior, proporcionalmente ao total de mulheres em cada categoria de Pclass, mulheres da primeira classe sobreviveram em maior número. Poucas mulheres da primeira e segunda classe morreram, as mulheres que morreram em geral pertenciam a classe 3.**
"""

#display(pd.crosstab([train_data['Sex'], train_data['Pclass']], train_data['Survived'], values=train_data['Age'], aggfunc='mean'))

display(pd.crosstab([train_data['Sex'], train_data['Pclass']], train_data['Survived']))

pd.crosstab([train_data['Sex'], train_data['Survived']], train_data['Pclass']).plot.bar()
plt.ylabel('Number of People')
plt.tick_params(axis='x', labelrotation=45)
plt.show()

"""> **Relação entre as features Pclass e Fare:**

> **Resposta Q3: O preço da passagem está relacionado com a classe ocupada? Sim, a primeira classe engloba passagens mais caras. Os outliers de cada classe podem ser explicados talvez pela data da compra (passagens compradas no dia tendem a ser mais caras, por exemplo).**
"""

sns.set()
plt.figure(figsize=(10, 8))
sns.boxplot(y='Fare', x='Pclass', data=train_data)

"""> **Relação entre as features Parch, SibSp, Parch_SibSp e Survived em relação aos homens:**

* Comparando homens acompanhados e sem nenhum acompanhante, nota-se que homens não acompanhados sobreviveram mais em números absolutos.

* Contudo, haviam mais homens não acompanhados do que acompanhados no navio. 

* Assim, homens não acompanhados morreram mais também. 

> **Resposta Q4: Desconsiderando mulheres e crianças, homens com acompanhantes tenderam a sobreviver mais? Não, homens não acompanhados sobreviveram em maior número.**

**> Resposta Q4: Ou ainda, homens ricos e acompanhados tiveram mais chances? Não, mesmo para homens ricos o padrão se manteve, homens não acompanhados sobreviveram mais.**
"""

##Homens acompanhados de um ou mais pais ou filhos versus sobrevivência
train_data[(train_data['Sex']=='male') & (train_data['Parch']>0)]['Survived'].value_counts(normalize=False).plot.bar(label='With Parch')
train_data[(train_data['Sex']=='male') & (train_data['Parch']==0)]['Survived'].value_counts(normalize=False).plot.bar(alpha=0.8, color='darkorange', width=0.3, label='WO Parch')
plt.xlabel('Survived')
plt.ylabel('Number of Men - Feature Parch')
plt.legend()
plt.tick_params(axis='x', labelrotation=0)
plt.show()

##Homens acompanhados de um ou mais irmãos ou conjuge versus sobrevivência
train_data[(train_data['Sex']=='male') & (train_data['SibSp']>0)]['Survived'].value_counts(normalize=False).plot.bar(label='With SibSp')
train_data[(train_data['Sex']=='male') & (train_data['SibSp']==0)]['Survived'].value_counts(normalize=False).plot.bar(alpha=0.8, color='darkorange', width=0.3, label='WO SibSp')
plt.xlabel('Survived')
plt.ylabel('Number of Men - Feature SibSp')
plt.legend()
plt.tick_params(axis='x', labelrotation=0)
plt.show()

##Homens acompanhados de um ou mais pais, filhos, irmãos ou conjuge versus sobrevivência
train_data[(train_data['Sex']=='male') & (train_data['Parch_SibSp']>0)]['Survived'].value_counts(normalize=False).plot.bar(label='With Parch_SibSp')
train_data[(train_data['Sex']=='male') & (train_data['Parch_SibSp']==0)]['Survived'].value_counts(normalize=False).plot.bar(alpha=0.8, color='darkorange', width=0.3, label='WO Parch_SibSp')
plt.xlabel('Survived')
plt.ylabel('Number of Men - Feature Parch_SibSp')
plt.legend()
plt.tick_params(axis='x', labelrotation=0)
plt.show()

##Homens da primeira classe acompanhados de um ou mais pais, filhos, irmãos ou conjuge versus sobrevivência
train_data[(train_data['Sex']=='male') & (train_data['Pclass']==1) & (train_data['Parch_SibSp']>0)]['Survived'].value_counts(normalize=False).plot.bar(label='With Parch_SibSp')
train_data[(train_data['Sex']=='male') & (train_data['Pclass']==1) & (train_data['Parch_SibSp']==0)]['Survived'].value_counts(normalize=False).plot.bar(alpha=0.8, color='darkorange', width=0.3, label='WO Parch_SibSp')
plt.xlabel('Survived')
plt.ylabel('Number of 1st Class Men - Feature Parch_SibSp')
plt.legend()
plt.tick_params(axis='x', labelrotation=0)
plt.show()

"""# **Correlation between features**

> Determinação do grau de relacionamento entre duas features. Caso os pontos das variáveis, representados num plano cartesiano (x, y) ou gráfico de dispersão, apresentem uma dispersão similar ao longo de uma reta imaginária, diz-se que os dados apresentam correlação linear que pode ser negativa (próxima à -1) ou positiva (próxima à 1). Caso não apresentem, o cálculo de correlação será igual à 0.

> **Porém, correlação não implica em causalidade.**

O fato de variáveis estarem correlacionados não quer dizer que uma *influência* no comportamento da outra. O padrão de comportamento pode estar associado a fatores externos sem relação entre si.

> **Aparentemente só há um cenário de correlação: Consiste na correlação entre as features Parch e Parch_SibSp, e Parch_SibSp e SibSp.**

* Isso se deve o fato de Parch_SibSp ser a soma dessas duas features.

* Parch e SibSp apresentam correlação baixa.

* Assim, seria possível considerar somente Parch_SibSp ou desconsiderá-la para considerar Parch e SibSp.
"""

corr=train_data.iloc[:, 1:].corr()
display(corr)

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))
# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""# **Feature transformation**

Transformation of nominal features to numerical features.

Operations applied to both train and test datasets.

* Feature Sex (str) para Sex_bin (binária)

* Feature Embarked (str) para Embarked_num (numérica)

* Feature Cabin_null representando valores ausentes de Cabin.
"""

##Transformation of nominal features to numerical features
def sex_to_bin(val):
    if val=='female':
        return 1
    else:
        return 0

def embarked_to_num(val):
    if val=='S':
        return 0
    elif val=='C':
        return 1
    elif val=='Q':
        return 2

train_data['Sex_bin']=train_data['Sex'].map(sex_to_bin)
test_data['Sex_bin']=test_data['Sex'].map(sex_to_bin)

train_data['Embarked_num']=train_data['Embarked'].map(embarked_to_num)
test_data['Embarked_num']=test_data['Embarked'].map(embarked_to_num)

#Booleans
train_data['Cabin_null']=train_data['Cabin'].isnull().astype(int) 
test_data['Cabin_null']=test_data['Cabin'].isnull().astype(int)

#train_data['Embarked_S']=(train_data['Embarked']=='S').astype(int) 
#test_data['Embarked_S']=(test_data['Embarked']=='S').astype(int)

#train_data['Embarked_C']=(train_data['Embarked']=='C').astype(int) 
#test_data['Embarked_C']=(test_data['Embarked']=='C').astype(int)

"""* Títulos existentes na feature Name utilizados como features individuais indicando possível importância de um certo passageiro.

* Títulos mais frequentes usados: (' Mr. ', 517), (' Miss. ', 182), (' Mrs. ', 125), (' Master. ', 40), (' Dr. ', 7), (' Rev. ', 6)

"""

##titles of names
names=train_data['Name'].unique()
name_re = re.compile('\w+\.')
#name_pref=list(set(name_re.findall(str(names)))) #remove duplicated strings
name_pref=[name_re.findall(str(n)) for n in names]
dict_name_pref={}
for n in name_pref:
  if n[0] in dict_name_pref:
    dict_name_pref[n[0]]+=1
  else:
    dict_name_pref[n[0]]=1
name_pref=sorted(dict_name_pref.items(), key=lambda x: x[1], reverse=True)
prefs=[]
for n in name_pref:
  if n[1]>1:
    prefs.append(n)
print(prefs)
##[(' Mr. ', 517), (' Miss. ', 182), (' Mrs. ', 125), (' Master. ', 40), (' Dr. ', 7), (' Rev. ', 6), (' Major. ', 2), (' Mlle. ', 2), (' Col. ', 2)]

train_data['Name_have_Miss']=train_data['Name'].str.contains(' Miss. ').astype(int)
train_data['Name_have_Mrs']=train_data['Name'].str.contains(' Mrs. ').astype(int)

train_data['Name_have_Mr']=train_data['Name'].str.contains(' Mr. ').astype(int)
train_data['Name_have_Master']=train_data['Name'].str.contains(' Master. ').astype(int)
train_data['Name_have_Dr']=train_data['Name'].str.contains(' Dr. ').astype(int)
train_data['Name_have_Rev']=train_data['Name'].str.contains(' Rev. ').astype(int)

test_data['Name_have_Miss']=test_data['Name'].str.contains(' Miss. ').astype(int)
test_data['Name_have_Mrs']=test_data['Name'].str.contains(' Mrs. ').astype(int)

test_data['Name_have_Mr']=test_data['Name'].str.contains(' Mr. ').astype(int)
test_data['Name_have_Master']=test_data['Name'].str.contains(' Master. ').astype(int)
test_data['Name_have_Dr']=test_data['Name'].str.contains(' Dr. ').astype(int)
test_data['Name_have_Rev']=test_data['Name'].str.contains(' Rev. ').astype(int)

"""# **Correlation between features II**

"""

corr=train_data.iloc[:, 1:].corr()
display(corr)

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))
# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""# **ML steps**

Problema a ser resolvido: Considerando as features do dataset, predizer um dado passageiro sobreviveu (1) ou não (0) de acordo com a feature-alvo Survived.

**Processo de ajuste do modelo de ML:**

1. Divisão da base em treino e validação (split).

2. Ajuste dos dados de treino (fit).

3. Predição e cálculo da acurácia para o conjunto de validação (score).

4. Predição no conjunto real de teste (prediction).

**Features para o modelo de ML:**

X = Features de treino\
y = Feature-alvo
"""

print(train_data.columns)

features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_bin', 'Embarked_num', 'Cabin_null', 'Name_have_Miss', 'Name_have_Mrs', 'Name_have_Mr', 'Name_have_Master', 'Name_have_Dr', 
             'Name_have_Rev']

"""**Train Definition**

"""

X = train_data[features]
y = train_data['Survived']
display(X.head())
display(y.head())

"""**Test Definition**"""

X_test=test_data[features]
display(X_test.head())

"""**Treat Data Missing**"""

#train
meds=X['Age'].median()
X['Age']=X['Age'].fillna(meds)
X['Embarked_num']=X['Embarked_num'].fillna(X['Embarked_num'].value_counts().index[0])

#test
X_test['Age']=X_test['Age'].fillna(meds)
X_test['Embarked_num']=X_test['Embarked_num'].fillna(X['Embarked_num'].value_counts().index[0])

"""# **Data split between train and validation datasets**

Para o train_test_split define-se:
(x_treino, x_teste, y_treino, y_teste)

Funçã de divisão:
train_test_split(X, y, test_size = 0.5)

Onde,

X -> vetor features

y -> variável resposta Survived

> teste_size = 0.5 -> tamanho para a base de teste (validação). A proporção entre treino e teste varia de acordo com o volume de dados disponível. Mas, usualmente, encontra-se proporções 50/50, 30/70, 25/75 ou 20/80. 

> Aqui, será testado com 0.5 ou 50%, o que significa que a base de treino será composta pelos 50% restantes.
"""

#np.random.seed(0)
train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.5, stratify=y, random_state=376) #test_size=0.3, 0.2
print(train_X.head())

"""# **ML model**

*Datasets:*

Train: train_X, train_y

Validation: val_X, val_y

Test: X_test

# **DummyClassifier algorithm: First Baseline**

O algoritmo base DummyClassifier necessita da definição da estratégia utilizada para ajustar o modelo.

DummyClassifier('most_frequent')

> Será empregada a estratégia de *dados mais frequentes*: dado o valor mais frequente da variável resposta (Survived), o modelo Dummy vai inferir que todos os registros da base de dados assumem aquele valor na feature target Survived. 

> Predição: função *predict()*. Recebe como parâmetro a base de validação val_X.

> Cálculo da acurácia: *accuracy_score function*. Recebe como parâmetros a base teste da variável resposta (val_y) e as previsões do modelo.

previsao_dummy = modelo_dummy.predict(x_teste)
accuracy_score(y_teste, previsao_dummy)

> **Como acurácia, o modelo DummyClassifier atingiu 0.617 (~62% das previsões corretas).**
"""

##modelo dummy 1
modelo_dummy = DummyClassifier('most_frequent', random_state=376)
modelo_dummy.fit(train_X, train_y) #treino
previsao_dummy = modelo_dummy.predict(val_X) #predição
accuracy_score(val_y, previsao_dummy) #cálculo de acurácia

"""# **Second Baseline**

Outro baseline está relacionado ao problema em questão: Sabe-se que mulheres e crianças tiveram prioridade no salvamento, confirmado pela análise prévia realizada.

Com base na etapa de EDA, o segundo baseline consiste em considerar que:

1. Mulheres sobreviveram.

2. Crianças menores de 15 anos sobreviveram.

3. Homens da classe 1 e sem acompanhantes sobreviveram.

4. O restante não sobreviveu.

> **Como acurácia, o segundo baseline atingiu 0.770 (~77% das previsões corretas).**
"""

##modelo dummy 2
control_predictions=((val_X['Sex_bin']==1) | (val_X['Age']<15) | ((val_X['Sex_bin']==0) & (val_X['Pclass']==1) & (val_X['Parch']==0) & (val_X['SibSp']==0))).astype(np.int64)
accuracy_score(val_y, control_predictions)

"""# **Logistic Regression algorithm**

Modelo de regressão logística modelo_rlogistica com max_iter = 1000.

Ajuste do modelo: modelo_rlogistica.fit(train_X, train_y)

Cálculo de acurácia: função modelo_rlogistica.score(val_X, val_y)

Score() quantas predições o modelo acertou na base de teste.

> **Como acurácia, o modelo de regressão logística atingiu 0,827 (~83% das previsões corretas).**
"""

##modelo de regressão logística
modelo_rlogistica = LogisticRegression(max_iter=1000, random_state=376)
modelo_rlogistica.fit(train_X, train_y) #treino
modelo_rlogistica.score(val_X, val_y) #predição e cálculo de acurácia

"""# **Decision Tree algorithm**

Modelo de árvore de decisão DecisionTreeClassifier com max_depth = 3.

> **Como acurácia, o modelo de árvore de decisão atingiu 0,807 (~81% das previsões corretas).**
"""

##modelo de árvore de decisão
modelo_arvore = DecisionTreeClassifier(max_depth = 3, random_state=376)
modelo_arvore.fit(train_X, train_y)
modelo_arvore.score(val_X, val_y)

"""**Representação da árvore de decisão com profundidade 3:**"""

fig, ax = plt.subplots(figsize=(15, 10), facecolor='k')
tree.plot_tree(modelo_arvore,
               ax=ax,
               fontsize=10,
               rounded=True,
               filled=True,
               feature_names=train_X.columns,
               class_names=['Not survived', 'Survived'])

plt.show()

"""**Variação como forma de otimização do parâmetro max_depth da árvore para tentar encontrar resultados melhores**

Variação do max_depth dentro de um intervalo de valores: entre 1 e 14 camadas.
"""

train=[]
valid=[]
for i in range(1,15):
    modelo_arvore = DecisionTreeClassifier(max_depth = i, random_state=376)
    modelo_arvore.fit(train_X, train_y)
    train.append(modelo_arvore.score(train_X, train_y))
    valid.append(modelo_arvore.score(val_X, val_y))
  
#comparação de acurácia
for i in range(len(train)): 
  print('max_depth:', i+1, 'score treino:', train[i], 'score validação:', valid[i])

"""**Problema de overfitting:**

Observando as diferenças entre os scores de treino e teste, percebe-se que inicialmente os valores de treino e teste são muito próximos, mas conforme a profundiade da árvore aumenta, os valores de acurácia para os dados de treino aumentam muito, enquanto esses mesmos valores para os dados de teste, caem (a diferença entre eles aumenta).

A medida em que o número de camadas aumenta, o modelo consegue capturar muito bem as características dos dados de treino, em particular.

Em contrapartida, o modelo não consegue generalizar de forma satisfatória as características dos dados de validação, então a acurácia vai caindo em relação ao conjunto de treino.

**Conforme o gráfico, o parâmetro ideal seria max_depth = 8.**
"""

plt.figure(figsize=(12, 8))
ax=sns.lineplot(x=range(1,15), y = train, label='treino')
ax=sns.lineplot(x=range(1,15), y = valid, label='validação')
ax.set(xlabel='max_depth', ylabel='Score')

"""Modelo de árvore de decisão DecisionTreeClassifier com max_depth = 8.

> **Como acurácia, o modelo de árvore de decisão atingiu 0,825 (~83% das previsões corretas).**
"""

modelo_arvore = DecisionTreeClassifier(max_depth = 8, random_state=376)
modelo_arvore.fit(train_X, train_y)
modelo_arvore.score(val_X, val_y)

"""# **Random Forest algorithm**

Random Forest gera várias árvores de decisão através de amostras aleatórias do conjunto de dados para, posteriormente, realizar as predições.

Random Forest com n_estimators=100.

> **Como acurácia, o modelo de árvore de decisão atingiu 0,829 (~83% das previsões corretas).**
"""

#rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)
rf_model = RandomForestClassifier(n_estimators=100, random_state=376)
rf_model.fit(train_X, train_y)
rf_val_predictions = rf_model.predict(val_X)
rf_model.score(val_X, val_y)

"""**Validação:**

Comparação das predições relizadas sobre os dados de validação com a saída esperada.
"""

##Comparison with the control submission (with only women)
control_predictions=(val_X['Sex_bin']==1).astype(np.int64)
print(np.mean(control_predictions==val_y))

"""**Cross Validation: *Kfold***"""

list_acc=[]

kf=RepeatedKFold(n_splits=2, n_repeats=10, random_state=10)

for l_train, l_val in kf.split(X):
  #print(l_train.shape[0], l_val.shape[0])
  train_X, val_X = X.iloc[l_train], X.iloc[l_val]
  train_y, val_y = y.iloc[l_train], y.iloc[l_val]

  ##training
  #rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)
  rf_model = LogisticRegression()

  rf_model.fit(train_X, train_y)
  ##prediction
  rf_val_predictions = rf_model.predict(val_X)

  acc=np.mean(rf_val_predictions==val_y)
  list_acc.append(acc)
print(np.mean(list_acc))

print(np.mean(list_acc))

"""**Error analysis of features: Improve results**

Comparing the predicted result with the expected output in recpect of the other variables
"""

val_X_check = train_data.iloc[l_val].copy()
val_X_check['Prediction'] = rf_val_predictions
val_X_check.head()
X_errors=val_X_check[val_X_check['Survived']!=val_X_check['Prediction']]
X_errors=X_errors[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex_bin',
       'Embarked_num', 'Prediction', 'Survived']]
#X_errors.describe()
X_errors.head()

X_women=X_errors[X_errors['Sex_bin']==1]
X_men=X_errors[X_errors['Sex_bin']==0]
#print(X_women.sort_values('Survived'))
print(X_men.sort_values('Survived'))

"""**Plotting results**"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %pylab inline
pylab.hist(list_acc)

"""**Test step**

Including the entire train and test sets
"""

##training
#rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)
rf_model = LogisticRegression()
rf_model.fit(X, y)

##prediction
rf_val_predictions = rf_model.predict(X_test)

"""**Save predictions in format used for Titanic competition scoring**"""

output = pd.DataFrame({'PassengerId': test_data.PassengerId,
                       'Survived': rf_val_predictions})

#output = pd.Series(rf_val_predictions, index=test_data['PassengerId'], name='Survived')

output.to_csv('submission.csv', header=True, index=False)
!head -n10 submission.csv
#files.download('submission.csv')